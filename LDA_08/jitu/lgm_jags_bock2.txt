model{
  
  for (i in 1:N){
    # observed variables
    ######################################################
    # # factor model
    # lavaan code
    # I  =~ 1*dep1+1*dep2+1*dep3+1*dep4+1*dep5+1*dep6
    # S1 =~ (-2.5)*dep1+(-1.5)*dep2+(-0.5)*dep3
    # S2 =~ 0.5*dep4+1.5*dep5+2.5*dep6
    ######################################################
    muy[i,1] <- eta[i,1]-2.5*eta[i,2];
    muy[i,2] <- eta[i,1]-1.5*eta[i,2];
    muy[i,3] <- eta[i,1]-0.5*eta[i,2];
    muy[i,4] <- eta[i,1]+0.5*eta[i,3];
    muy[i,5] <- eta[i,1]+1.5*eta[i,3];
    muy[i,6] <- eta[i,1]+2.5*eta[i,3];
    
    ######################################################
    #latent variables
    # this is a group-specific model (with group specific means.
    # each time the factor x[i] indicates 1 or 2 (recode in data)
    ######################################################
    mueta[i,1] <- beta0[1,x[i]]
    mueta[i,2] <- beta0[2,x[i]]
    mueta[i,3] <- beta0[3,x[i]]
  }
  
  
  
  #///////////////////////////////////
  #// distribution of y, again group-specific
  #///////////////////////////////////
  for(i in 1:N){
    for(k in 1:6) {
      y[i,k] ~ dnorm(muy[i,k],psiy[k,x[i]]);
    }
  
    #///////////////////////////////////
    #// distribution of factors
    #// again group-specific
    #///////////////////////////////////
    eta[i,1:3] ~ dmnorm(mueta[i,1:3],psieta[1:3,1:3,x[i]]);
  }

  #///////////////////////////////////
  #// priors
  #///////////////////////////////////
  
  for(j in 1:2){
    # is now 3x2 (see lines 24-26)
    # regression coefficients 
    for(k in 1:3){
      beta0[k,j] ~ dnorm(0,0.01);
    }
    
    #precisions
    for(k in 1:6){
      psiy[k,j] ~ dgamma(1,1);
    }
  
    psieta[1:3,1:3,j] ~ dwish(psi0[1:3,1:3],3);
  }
  #///////////////////////////////////
  # transformations
  #///////////////////////////////////
  for(j in 1:2){
    for(k in 1:6){sigmay[k,j] <- 1/psiy[k,j]}
    sigmaeta[1:3,1:3,j] <- inverse(psieta[1:3,1:3,j])
  
  }
  
  
}

